{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f337b51",
   "metadata": {},
   "source": [
    "## Step 1: Get all markdown files recursively\n",
    "This cell finds every .md file in your Obsidian Vault, including subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68066baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 markdown files\n",
      "\n",
      "First 5 files:\n",
      "C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Clippings\\An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\Terminologies to Master First.md\n",
      "C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\The Pharma Overview.md\n",
      "C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Training Videos\\June 10th\\Trust Based Discount.md\n",
      "C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Training Videos\\SQL Training\\Overall.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the root folder\n",
    "vault_path = r\"C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\KPI Family\"\n",
    "\n",
    "# Get all markdown files recursively\n",
    "markdown_files = list(Path(vault_path).rglob(\"*.md\"))\n",
    "\n",
    "print(f\"Found {len(markdown_files)} markdown files\")\n",
    "print(\"\\nFirst 5 files:\")\n",
    "for file in markdown_files[:5]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017124a2",
   "metadata": {},
   "source": [
    "## Step 2: Map the folder structure\n",
    "This cell gives you a breakdown of folders, subfolders, and file counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folders with markdown files: 32\n",
      "\n",
      "Files per folder:\n",
      "  8 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\Cheat Sheets\\2. Clinical Trials\n",
      "  7 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\The Training Document\\2.7 Input Files\n",
      "  7 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\Cheat Sheets\\3. Supply Chain & Manufacturing\n",
      "  7 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\Cheat Sheets\\4. Market Access\n",
      "  5 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\The Training Document\\2.3 Drug Distribution Area\n",
      "  5 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\The Training Document\\3.0 Appendix\n",
      "  4 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\KPI Family\n",
      "  4 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\Phases\n",
      "  4 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\The Training Document\\1.8 Payer\n",
      "  4 files | C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\The Training Document\\1.9 Payer Analytics\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Analyze folder structure\n",
    "folder_stats = defaultdict(int)\n",
    "\n",
    "for file in markdown_files:\n",
    "    folder = file.parent\n",
    "    folder_stats[folder] += 1\n",
    "\n",
    "print(f\"Total folders with markdown files: {len(folder_stats)}\\n\")\n",
    "print(\"Files per folder:\")\n",
    "for folder, count in sorted(folder_stats.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{count:3d} files | {folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b214b5",
   "metadata": {},
   "source": [
    "## Step 3: Extract existing YAML frontmatter (if any)\n",
    "Before we start writing properties, let's see what's already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing file: An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "\n",
      "Existing YAML frontmatter:\n",
      "title: An Introduction to Market Access in the Pharmaceutical Industry\n",
      "source: https://www.rxcomms.com/learning/guide-to-market-access-in-the-pharmaceutical-industry\n",
      "author: RXComms\n",
      "published: 01-01-2024\n",
      "created: 2025-11-24\n",
      "description: Understand the role of Market Access in the Pharma sector. Explore its challenges, global perspective, and relevance to drug development and Biotech.\n",
      "tags:\n",
      "  - clippings\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_yaml_frontmatter(file_path):\n",
    "    \"\"\"Extract YAML frontmatter from a markdown file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Match YAML frontmatter (--- at start and end)\n",
    "    match = re.match(r'^---\\s*\\n(.*?)\\n---\\s*\\n', content, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)  # Return YAML content\n",
    "    return None\n",
    "\n",
    "# Test on first file\n",
    "sample_file = markdown_files[0]\n",
    "yaml_content = extract_yaml_frontmatter(sample_file)\n",
    "\n",
    "print(f\"Testing file: {sample_file.name}\\n\")\n",
    "if yaml_content:\n",
    "    print(\"Existing YAML frontmatter:\")\n",
    "    print(yaml_content)\n",
    "else:\n",
    "    print(\"No YAML frontmatter found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116064dd",
   "metadata": {},
   "source": [
    "Why this matters:\n",
    "\n",
    "- Some files might already have YAML properties\n",
    "- We don't want to overwrite them blindly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d61c0e",
   "metadata": {},
   "source": [
    "## Step 4: Get file metadata (Created Date)\n",
    "This extracts the file creation date from the OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e16a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "Created: 2025-11-24\n",
      "Modified: 2025-11-24\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_file_metadata(file_path):\n",
    "    \"\"\"Get file creation and modification dates.\"\"\"\n",
    "    stat = file_path.stat()\n",
    "    \n",
    "    created = datetime.fromtimestamp(stat.st_ctime)\n",
    "    modified = datetime.fromtimestamp(stat.st_mtime)\n",
    "    \n",
    "    return {\n",
    "        'created': created.strftime('%Y-%m-%d'),\n",
    "        'modified': modified.strftime('%Y-%m-%d')\n",
    "    }\n",
    "\n",
    "# Test on first file\n",
    "metadata = get_file_metadata(markdown_files[0])\n",
    "print(f\"File: {markdown_files[0].name}\")\n",
    "print(f\"Created: {metadata['created']}\")\n",
    "print(f\"Modified: {metadata['modified']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f4ec4",
   "metadata": {},
   "source": [
    "Why this approach:\n",
    "\n",
    "- st_ctime = creation time (Windows) or last metadata change (Unix)\n",
    "- st_mtime = last modification time\n",
    "- Format as YYYY-MM-DD (Obsidian-friendly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b61ea",
   "metadata": {},
   "source": [
    "## Step 5: Draft YAML property insertion function\n",
    "This is the core function that will add YAML frontmatter to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_yaml_properties(file_path, properties, overwrite=False):\n",
    "    \"\"\"\n",
    "    Add YAML frontmatter to a markdown file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the markdown file\n",
    "        properties: Dict of properties to add (e.g., {'created': '2025-01-01', 'area': 'Projects'})\n",
    "        overwrite: If True, replace existing YAML. If False, skip files with YAML.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Check if YAML already exists\n",
    "    has_yaml = content.startswith('---\\n')\n",
    "    \n",
    "    if has_yaml and not overwrite:\n",
    "        print(f\"Skipped (has YAML): {file_path.name}\")\n",
    "        return False\n",
    "    \n",
    "    # Build YAML frontmatter\n",
    "    yaml_lines = ['---']\n",
    "    for key, value in properties.items():\n",
    "        yaml_lines.append(f'{key}: {value}')\n",
    "    yaml_lines.append('---\\n')\n",
    "    \n",
    "    yaml_block = '\\n'.join(yaml_lines)\n",
    "    \n",
    "    # If overwriting, remove old YAML\n",
    "    if has_yaml:\n",
    "        content = re.sub(r'^---\\s*\\n.*?\\n---\\s*\\n', '', content, flags=re.DOTALL)\n",
    "    \n",
    "    # Add new YAML at the top\n",
    "    new_content = yaml_block + content\n",
    "    \n",
    "    # Write back to file\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(new_content)\n",
    "    \n",
    "    print(f\"Updated: {file_path.name}\")\n",
    "    return True\n",
    "\n",
    "# Test on a COPY of a file (don't modify the original yet)\n",
    "# We'll do a dry-run test in the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfc58e",
   "metadata": {},
   "source": [
    "### Why this design:\n",
    "\n",
    "- overwrite=False by default = safe mode\n",
    "- Strips existing YAML before adding new one (if overwriting)\n",
    "- Returns True/False so you can track success\n",
    "\n",
    "\n",
    "Next Steps (Before We Run This)\n",
    "Before we execute the YAML insertion, let's:\n",
    "\n",
    "Brainstorm the property values (like you mentioned)\n",
    "\n",
    "created: Auto-populated from file metadata\n",
    "area: Should this be based on folder name? Or manual tagging?\n",
    "tag: Do you want default tags, or should we parse existing #tags in the content?\n",
    "\n",
    "\n",
    "Test on a single file (or a copy) to make sure it works\n",
    "Decide on batch processing strategy:\n",
    "\n",
    "Process all files at once?\n",
    "- Only files without YAML?\n",
    "- Only files in specific folders?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75af59c",
   "metadata": {},
   "source": [
    "## Step 6: Define Area from folder path\n",
    "We'll use the parent folder name as the area. This gives meaningful context without being too granular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fee767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area extraction examples:\n",
      "\n",
      "Clippings                 | An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "Pharma Domain             | Terminologies to Master First.md\n",
      "Pharma Domain             | The Pharma Overview.md\n",
      "Training Videos           | Trust Based Discount.md\n",
      "Training Videos           | Overall.md\n",
      "Pharma Domain             | Commercial (Sales & Marketing KPIs).md\n",
      "Pharma Domain             | Manufacturing & Supply Chain KPIs.md\n",
      "Pharma Domain             | Quality & Regulatory Affairs KPIs.md\n",
      "Pharma Domain             | R&D KPIs.md\n",
      "Pharma Domain             | Phase 1 - Foundations.md\n"
     ]
    }
   ],
   "source": [
    "def extract_area_from_path(file_path, vault_root):\n",
    "    \"\"\"\n",
    "    Extract area from folder structure.\n",
    "    Uses the first subfolder under vault root as the area.\n",
    "    \"\"\"\n",
    "    # Get relative path from vault root\n",
    "    relative_path = file_path.relative_to(vault_root)\n",
    "    \n",
    "    # Get all parent folders\n",
    "    parts = relative_path.parts[:-1]  # Exclude the filename itself\n",
    "    \n",
    "    if len(parts) == 0:\n",
    "        return \"Root\"  # File is directly in vault root\n",
    "    elif len(parts) == 1:\n",
    "        return parts[0]  # File is in a top-level folder\n",
    "    else:\n",
    "        # File is nested - use the top-level folder as area\n",
    "        return parts[0]\n",
    "\n",
    "# Test on sample files\n",
    "vault_root = Path(r\"C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\KPI Family\")\n",
    "\n",
    "print(\"Area extraction examples:\\n\")\n",
    "for file in markdown_files[:10]:\n",
    "    area = extract_area_from_path(file, vault_root)\n",
    "    print(f\"{area:25s} | {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd96e35",
   "metadata": {},
   "source": [
    "Why this works:\n",
    "\n",
    "- Files under Pharma Domain\\Cheat Sheets\\... → Area = Pharma Domain\n",
    "- Files under Pharma Domain\\The Training Document\\... → Area = Pharma Domain\n",
    "- Keeps it simple and consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4caf91",
   "metadata": {},
   "source": [
    "# Step 7: Define Tags from filename\n",
    "We'll extract tags from the filename using a few strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeddd32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag extraction examples:\n",
      "\n",
      "An Introduction to Market Access in the Pharmaceutical Industry.md → ['introduction', 'market', 'access', 'pharmaceutical', 'industry']\n",
      "Terminologies to Master First.md                   → ['terminologies', 'master', 'first']\n",
      "The Pharma Overview.md                             → ['pharma', 'overview']\n",
      "Trust Based Discount.md                            → ['trust', 'based', 'discount']\n",
      "Overall.md                                         → ['overall']\n",
      "Commercial (Sales & Marketing KPIs).md             → ['commercial', '(sales', '&', 'marketing', 'kpis)']\n",
      "Manufacturing & Supply Chain KPIs.md               → ['manufacturing', '&', 'supply', 'chain', 'kpis']\n",
      "Quality & Regulatory Affairs KPIs.md               → ['quality', '&', 'regulatory', 'affairs', 'kpis']\n",
      "R&D KPIs.md                                        → ['r&d', 'kpis']\n",
      "Phase 1 - Foundations.md                           → ['phase', 'foundations']\n"
     ]
    }
   ],
   "source": [
    "def extract_tags_from_filename(file_path):\n",
    "    \"\"\"\n",
    "    Extract tags from filename.\n",
    "    \n",
    "    Strategies:\n",
    "    1. Split on common separators (-, _, spaces)\n",
    "    2. Remove common words (the, a, an, etc.)\n",
    "    3. Convert to lowercase\n",
    "    4. Return as list\n",
    "    \"\"\"\n",
    "    # Get filename without extension\n",
    "    filename = file_path.stem\n",
    "    \n",
    "    # Common words to exclude from tags\n",
    "    stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with'}\n",
    "    \n",
    "    # Split on separators and clean\n",
    "    tokens = re.split(r'[-_\\s]+', filename.lower())\n",
    "    \n",
    "    # Remove stopwords and numbers-only tokens\n",
    "    tags = [\n",
    "        token for token in tokens \n",
    "        if token and token not in stopwords and not token.isdigit()\n",
    "    ]\n",
    "    \n",
    "    # Limit to top 3-5 tags (avoid tag explosion)\n",
    "    return tags[:5]\n",
    "\n",
    "# Test on sample files\n",
    "print(\"Tag extraction examples:\\n\")\n",
    "for file in markdown_files[:10]:\n",
    "    tags = extract_tags_from_filename(file)\n",
    "    print(f\"{file.name:50s} → {tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e246d9",
   "metadata": {},
   "source": [
    "Why this approach:\n",
    "\n",
    "Converts Clinical-Trial-Phases.md → ['clinical', 'trial', 'phases']\n",
    "Removes noise words like \"the\", \"and\"\n",
    "Limits tags to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c712d",
   "metadata": {},
   "source": [
    "# Step 8: Combine everything into a processing function\n",
    "Now let's put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd8f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRY RUN: Processing first 3 files...\n",
      "\n",
      "\n",
      "============================================================\n",
      "File: An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "Path: Clippings\\An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "\n",
      "Proposed YAML:\n",
      "---\n",
      "created: 2025-11-24\n",
      "area: Clippings\n",
      "tags: ['introduction', 'market', 'access', 'pharmaceutical', 'industry']\n",
      "---\n",
      "Skipped (has YAML): An Introduction to Market Access in the Pharmaceutical Industry.md\n",
      "\n",
      "============================================================\n",
      "File: Terminologies to Master First.md\n",
      "Path: Pharma Domain\\Terminologies to Master First.md\n",
      "\n",
      "Proposed YAML:\n",
      "---\n",
      "created: 2025-11-24\n",
      "area: Pharma Domain\n",
      "tags: ['terminologies', 'master', 'first']\n",
      "---\n",
      "Updated: Terminologies to Master First.md\n",
      "\n",
      "============================================================\n",
      "File: The Pharma Overview.md\n",
      "Path: Pharma Domain\\The Pharma Overview.md\n",
      "\n",
      "Proposed YAML:\n",
      "---\n",
      "created: 2025-11-24\n",
      "area: Pharma Domain\n",
      "tags: ['pharma', 'overview']\n",
      "---\n",
      "Updated: The Pharma Overview.md\n"
     ]
    }
   ],
   "source": [
    "def process_markdown_file(file_path, vault_root, overwrite=False, dry_run=True):\n",
    "    \"\"\"\n",
    "    Add YAML properties to a markdown file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to markdown file\n",
    "        vault_root: Root of Obsidian vault\n",
    "        overwrite: Replace existing YAML if True\n",
    "        dry_run: If True, only print what would be done (don't modify files)\n",
    "    \"\"\"\n",
    "    # Extract metadata\n",
    "    metadata = get_file_metadata(file_path)\n",
    "    area = extract_area_from_path(file_path, vault_root)\n",
    "    tags = extract_tags_from_filename(file_path)\n",
    "    \n",
    "    # Build properties dict\n",
    "    properties = {\n",
    "        'created': metadata['created'],\n",
    "        'area': area,\n",
    "        'tags': tags  # Obsidian accepts list format\n",
    "    }\n",
    "    \n",
    "    # Show what we'd do\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"File: {file_path.name}\")\n",
    "    print(f\"Path: {file_path.relative_to(vault_root)}\")\n",
    "    print(f\"\\nProposed YAML:\")\n",
    "    print(\"---\")\n",
    "    print(f\"created: {properties['created']}\")\n",
    "    print(f\"area: {properties['area']}\")\n",
    "    print(f\"tags: {properties['tags']}\")\n",
    "    print(\"---\")\n",
    "    \n",
    "    if dry_run:\n",
    "        print(\"\\n[DRY RUN] No changes made\")\n",
    "        return False\n",
    "    else:\n",
    "        return add_yaml_properties(file_path, properties, overwrite)\n",
    "\n",
    "# Test on first 3 files (dry run)\n",
    "vault_root = Path(r\"C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\\Pharma Domain\\KPI Family\")\n",
    "\n",
    "print(\"DRY RUN: Processing first 3 files...\\n\")\n",
    "for file in markdown_files[:3]:\n",
    "    process_markdown_file(file, vault_root, dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d31b5",
   "metadata": {},
   "source": [
    "## Step 9: Batch process all files\n",
    "Once you're happy with the dry-run output, run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136eeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_vault(markdown_files, vault_root, overwrite=False, dry_run=False):\n",
    "    \"\"\"\n",
    "    Process all markdown files in the vault.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'updated': 0,\n",
    "        'skipped': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    for file in markdown_files:\n",
    "        try:\n",
    "            success = process_markdown_file(file, vault_root, overwrite, dry_run)\n",
    "            if success:\n",
    "                results['updated'] += 1\n",
    "            else:\n",
    "                results['skipped'] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR processing {file.name}: {e}\")\n",
    "            results['errors'] += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BATCH PROCESSING COMPLETE\")\n",
    "    print(f\"Updated: {results['updated']}\")\n",
    "    print(f\"Skipped: {results['skipped']}\")\n",
    "    print(f\"Errors: {results['errors']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# When you're ready to run for real:\n",
    "# batch_process_vault(markdown_files, vault_root, overwrite=False, dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d66eb",
   "metadata": {},
   "source": [
    "Before you run this for real:\n",
    "Test the dry-run output above and check:\n",
    "\n",
    "- Does the area look correct? (Should all be Pharma Domain based on your folder structure)\n",
    "- Do the tags make sense from the filenames?\n",
    "- Are the created dates accurate?\n",
    "\n",
    "If everything looks good, change dry_run=False and let it rip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f91e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION\n",
    "# ========================================\n",
    "vault_path = r\"C:\\Users\\BalasubramanianPG\\Videos\\Obsidian Vault\"\n",
    "vault_root = Path(vault_path)\n",
    "\n",
    "# ========================================\n",
    "# STEP 1: GET ALL MARKDOWN FILES (RECURSIVE)\n",
    "# ========================================\n",
    "def get_all_markdown_files(root_path):\n",
    "    \"\"\"Recursively get all .md files in all subfolders.\"\"\"\n",
    "    return list(Path(root_path).rglob(\"*.md\"))\n",
    "\n",
    "# ========================================\n",
    "# STEP 2: EXTRACT METADATA\n",
    "# ========================================\n",
    "def get_file_metadata(file_path):\n",
    "    \"\"\"Get file creation date.\"\"\"\n",
    "    stat = file_path.stat()\n",
    "    created = datetime.fromtimestamp(stat.st_ctime)\n",
    "    return created.strftime('%Y-%m-%d')\n",
    "\n",
    "def extract_area_from_path(file_path, vault_root):\n",
    "    \"\"\"Extract area from the top-level folder.\"\"\"\n",
    "    relative_path = file_path.relative_to(vault_root)\n",
    "    parts = relative_path.parts[:-1]  # Exclude filename\n",
    "    \n",
    "    if len(parts) == 0:\n",
    "        return \"Root\"\n",
    "    else:\n",
    "        return parts[0]  # Top-level folder = area\n",
    "\n",
    "def extract_tags_from_filename(file_path):\n",
    "    \"\"\"Extract tags from filename.\"\"\"\n",
    "    filename = file_path.stem\n",
    "    stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with'}\n",
    "    \n",
    "    # Split on separators\n",
    "    tokens = re.split(r'[-_\\s]+', filename.lower())\n",
    "    \n",
    "    # Filter stopwords and numbers\n",
    "    tags = [\n",
    "        token for token in tokens \n",
    "        if token and token not in stopwords and not token.isdigit()\n",
    "    ]\n",
    "    \n",
    "    return tags[:5]  # Limit to 5 tags\n",
    "\n",
    "# ========================================\n",
    "# STEP 3: ADD YAML FRONTMATTER\n",
    "# ========================================\n",
    "def add_yaml_properties(file_path, properties, overwrite=False):\n",
    "    \"\"\"\n",
    "    Add YAML frontmatter to markdown file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the markdown file\n",
    "        properties: Dict of properties {'created': '2025-01-01', 'area': 'X', 'tags': ['a', 'b']}\n",
    "        overwrite: If True, replace existing YAML\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading {file_path.name}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if YAML already exists\n",
    "    has_yaml = content.startswith('---\\n')\n",
    "    \n",
    "    if has_yaml and not overwrite:\n",
    "        return False  # Skip files with existing YAML\n",
    "    \n",
    "    # Build YAML frontmatter\n",
    "    yaml_lines = ['---']\n",
    "    yaml_lines.append(f\"created: {properties['created']}\")\n",
    "    yaml_lines.append(f\"area: {properties['area']}\")\n",
    "    \n",
    "    # Format tags as YAML list\n",
    "    if properties['tags']:\n",
    "        yaml_lines.append('tags:')\n",
    "        for tag in properties['tags']:\n",
    "            yaml_lines.append(f\"  - {tag}\")\n",
    "    else:\n",
    "        yaml_lines.append('tags: []')\n",
    "    \n",
    "    yaml_lines.append('---\\n')\n",
    "    yaml_block = '\\n'.join(yaml_lines)\n",
    "    \n",
    "    # If overwriting, remove old YAML\n",
    "    if has_yaml:\n",
    "        content = re.sub(r'^---\\s*\\n.*?\\n---\\s*\\n', '', content, flags=re.DOTALL)\n",
    "    \n",
    "    # Add new YAML at top\n",
    "    new_content = yaml_block + content\n",
    "    \n",
    "    # Write back\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(new_content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR writing {file_path.name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========================================\n",
    "# STEP 4: PROCESS SINGLE FILE\n",
    "# ========================================\n",
    "def process_markdown_file(file_path, vault_root, overwrite=False, dry_run=True):\n",
    "    \"\"\"Process a single markdown file.\"\"\"\n",
    "    # Extract metadata\n",
    "    created_date = get_file_metadata(file_path)\n",
    "    area = extract_area_from_path(file_path, vault_root)\n",
    "    tags = extract_tags_from_filename(file_path)\n",
    "    \n",
    "    properties = {\n",
    "        'created': created_date,\n",
    "        'area': area,\n",
    "        'tags': tags\n",
    "    }\n",
    "    \n",
    "    if dry_run:\n",
    "        # Just show what would be done\n",
    "        relative_path = file_path.relative_to(vault_root)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"File: {file_path.name}\")\n",
    "        print(f\"Path: {relative_path}\")\n",
    "        print(f\"\\nWould add YAML:\")\n",
    "        print(\"---\")\n",
    "        print(f\"created: {properties['created']}\")\n",
    "        print(f\"area: {properties['area']}\")\n",
    "        print(f\"tags:\")\n",
    "        for tag in properties['tags']:\n",
    "            print(f\"  - {tag}\")\n",
    "        print(\"---\")\n",
    "        return False\n",
    "    else:\n",
    "        return add_yaml_properties(file_path, properties, overwrite)\n",
    "\n",
    "# ========================================\n",
    "# STEP 5: BATCH PROCESS ALL FILES\n",
    "# ========================================\n",
    "def batch_process_vault(vault_root, overwrite=False, dry_run=True):\n",
    "    \"\"\"Process all markdown files in vault.\"\"\"\n",
    "    \n",
    "    # Get all markdown files\n",
    "    markdown_files = get_all_markdown_files(vault_root)\n",
    "    \n",
    "    print(f\"Found {len(markdown_files)} markdown files\")\n",
    "    print(f\"Overwrite existing YAML: {overwrite}\")\n",
    "    print(f\"Dry run mode: {dry_run}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    results = {\n",
    "        'total': len(markdown_files),\n",
    "        'updated': 0,\n",
    "        'skipped': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    for i, file in enumerate(markdown_files, 1):\n",
    "        try:\n",
    "            success = process_markdown_file(file, vault_root, overwrite, dry_run)\n",
    "            \n",
    "            if not dry_run:\n",
    "                if success:\n",
    "                    results['updated'] += 1\n",
    "                    print(f\"[{i}/{results['total']}] ✓ Updated: {file.name}\")\n",
    "                else:\n",
    "                    results['skipped'] += 1\n",
    "                    print(f\"[{i}/{results['total']}] ⊘ Skipped: {file.name}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['errors'] += 1\n",
    "            print(f\"[{i}/{results['total']}] ✗ ERROR: {file.name} - {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BATCH PROCESSING COMPLETE\")\n",
    "    print(f\"Total files: {results['total']}\")\n",
    "    print(f\"Updated: {results['updated']}\")\n",
    "    print(f\"Skipped: {results['skipped']}\")\n",
    "    print(f\"Errors: {results['errors']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ========================================\n",
    "# EXECUTION\n",
    "# ========================================\n",
    "\n",
    "# DRY RUN FIRST (shows first 5 files as examples)\n",
    "print(\"=\"*70)\n",
    "print(\"DRY RUN: Showing first 5 files\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "markdown_files = get_all_markdown_files(vault_root)\n",
    "for file in markdown_files[:5]:\n",
    "    process_markdown_file(file, vault_root, overwrite=False, dry_run=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Review the YAML output above\")\n",
    "print(\"2. If it looks good, run the FULL dry run:\")\n",
    "print(\"   batch_process_vault(vault_root, overwrite=False, dry_run=True)\")\n",
    "print(\"\\n3. If everything looks correct, run FOR REAL:\")\n",
    "print(\"   batch_process_vault(vault_root, overwrite=False, dry_run=False)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
